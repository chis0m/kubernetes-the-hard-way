## Prepare the etcd database
Etcd stores the cluster's state, the actual and desired states.
Kubernetes is stateless, all its stateful data needs to be stored somewhere, that is etcd.
Since K8 is distributed, it also needs a distributed storage.
All the configurations of K8 are stored in the form of key/value pair in etcd.
For security reasons, we want to encrypt data at rest in etcd.
Etcd is intelligent enough to watch for changes made on one instance and immediately replicate those changes in other instances.
In this project etcd listens on port `2379` from other components but communicates with other etcd on port `2380`

Note: All what is to be done below has been automated by `etcd.sh` script

1. Generate the encryption key and encode it using base64
```bash
ETCD_ENCRYPTION_KEY=$(head -c 32 /dev/urandom | base64)
```

1. Create an encryption-config.yaml
```bash
cat > etcd/encryption-config.yaml <<EOF
kind: EncryptionConfig
apiVersion: v1
resources:
  - resources:
      - secrets
    providers:
      - aescbc:
          keys:
            - name: key1
              secret: ${ETCD_ENCRYPTION_KEY}
      - identity: {}
EOF
```

2. Copy the `encryption-config.yaml` to all the master nodes
```bash
for i in 0 1 2; do
instance="${NAME}-Cluster-Master-${i}" \
  external_ip=$(aws ec2 describe-instances \
    --filters "Name=tag:Name,Values=${instance}" \
    --output text --query 'Reservations[].Instances[].PublicIpAddress')
  scp -i ${SSH_KEY} \
    -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no \
    etcd/encryption-config.yaml \
    ubuntu@${external_ip}:~/;
done
```

### Bootstrap Etcd Cluster
1. Get the public ips of the three master nodes
2. SSH into each master nodes
3. bootstrap the etcd

```bash
for i in 0 1 2; do
# get public ip  
instance="${NAME}-Cluster-Master-${i}" \
  external_ip=$(aws ec2 describe-instances \
    --filters "Name=tag:Name,Values=${instance}" \
    --output text --query 'Reservations[].Instances[].PublicIpAddress')
 # make installation script executable   
  chmod +x etcd/install_etcd.sh
# ssh into the master node and execute the script  
  ssh -i ${SSH_KEY} \
   -o StrictHostKeyChecking=no \
    ubuntu@${external_ip} \
    "bash -s" < etcd/install_etcd.sh
done
```
Note: I split the installation script into 2, and they are `install_etcd.sh`, `enable_etcd.sh`, this is in order to successfully complete the task

#### Content of the installation scripts to bootstrap etcd
1. Download etcd binary
```bash
wget -q --show-progress --https-only --timestamping \
  "https://github.com/etcd-io/etcd/releases/download/v3.4.15/etcd-v3.4.15-linux-amd64.tar.gz"
```

2. Extract and move the etcd server and etcd command line utility `etcdctl`
```bash
tar -xvf etcd-v3.4.15-linux-amd64.tar.gz
sudo mv etcd-v3.4.15-linux-amd64/etcd* /usr/local/bin/
```

3. Create a necessary directory and mv certificates
```bash
sudo mkdir -p /etc/etcd /var/lib/etcd
sudo chmod 700 /var/lib/etcd
# move required certificates
sudo cp ${HOME}/{ca.pem,master-kubernetes-key.pem,master-kubernetes.pem} /etc/etcd/
```

4. 
```bash
# Get Internal IP of the instance
export INTERNAL_IP=$(curl -s http://169.254.169.254/latest/meta-data/local-ipv4)
```

5. Each of the three etcd must have a unique name, here we are using the Private IP address of its own node
```bash
ETCD_NAME=$(curl -s http://169.254.169.254/latest/user-data)
```

7. Create the `etcd.service` systemd unit file
```bash
# Set cluster names and addresses
CLUSTER0=MC-K8-Cluster-Master-0
CLUSTER1=MC-K8-Cluster-Master-1
CLUSTER2=MC-K8-Cluster-Master-2

ADDRESS0=https://10.0.1.20:2380
ADDRESS1=https://10.0.1.21:2380
ADDRESS2=https://10.0.1.22:2380

# Create Etcd Service
cat <<EOF | sudo tee /etc/systemd/system/etcd.service
[Unit]
Description=etcd
Documentation=https://github.com/coreos

[Service]
Type=notify
ExecStart=/usr/local/bin/etcd \\
  --name ${ETCD_NAME} \\
  --trusted-ca-file=/etc/etcd/ca.pem \\
  --peer-trusted-ca-file=/etc/etcd/ca.pem \\
  --peer-client-cert-auth \\
  --client-cert-auth \\
  --listen-peer-urls https://${INTERNAL_IP}:2380 \\
  --listen-client-urls https://${INTERNAL_IP}:2379,https://127.0.0.1:2379 \\
  --advertise-client-urls https://${INTERNAL_IP}:2379 \\
  --initial-cluster-token etcd-cluster-0 \\
  --initial-cluster ${CLUSTER0}=${ADDRESS0},${CLUSTER1}=${ADDRESS1},${CLUSTER2}=${ADDRESS2} \\
  --cert-file=/etc/etcd/master-kubernetes.pem \\
  --key-file=/etc/etcd/master-kubernetes-key.pem \\
  --peer-cert-file=/etc/etcd/master-kubernetes.pem \\
  --peer-key-file=/etc/etcd/master-kubernetes-key.pem \\
  --initial-advertise-peer-urls https://${INTERNAL_IP}:2380 \\
  --initial-cluster-state new \\
  --data-dir=/var/lib/etcd
Restart=on-failure
RestartSec=5

[Install]
WantedBy=multi-user.target
EOF
```

7. start and enable etcd server
```bash
sudo systemctl daemon-reload
sudo systemctl enable etcd
sudo systemctl start etcd
```

8. Check if all worked well
This will get all etcd cluster members
```bash
sudo ETCDCTL_API=3 etcdctl member list \
  --endpoints=https://127.0.0.1:2379 \
  --cacert=/etc/etcd/ca.pem \
  --cert=/etc/etcd/master-kubernetes.pem \
  --key=/etc/etcd/master-kubernetes-key.pem
```

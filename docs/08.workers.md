## Bootstrapping components on the worker nodes
1. SSH into each worker node
Check kubeconfig.md to see how
2. Install OS dependencies
```bash
sudo apt-get update
sudo apt-get -y install socat conntrack ipset
```

- socat: Socat is the default implementation for Kubernetes port-forwarding when using dockershim for the kubelet runtime.
- Dockershim: was a temporary solution proposed by the Kubernetes community to add support for Docker so that it could serve as its container runtime
- Conntrack: Allows the linux kernel to keep track of all logical network connections or flows.
  It is essential for performant complex networking of Kubernetes where nodes need to track connection information between thousands of pods and services
- ipset: is an extension to iptables which is used to configure firewall rules on a Linux server. 
  Kubernetes uses ipsets to implement a distributed firewall solution that enforces network policies within the cluster

3. Disable swap 
If `swap` is not disabled, kubelet will not start. It is highly recommended to allow Kubernetes to handle resource allocation
```bash
# check if swap is enabled
sudo swapon --show

# if enabled
sudo swapoff -a
```

4. Download and install a container runtime
We will be using `containerd` because kubernetes(v1.24) will stop the use of dockershim which provides support for docker in k8
   
```bash
# Download binaries for runc, cri-ctl, and containerd
 wget https://github.com/opencontainers/runc/releases/download/v1.0.0-rc93/runc.amd64 \
  https://github.com/kubernetes-sigs/cri-tools/releases/download/v1.21.0/crictl-v1.21.0-linux-amd64.tar.gz \
  https://github.com/containerd/containerd/releases/download/v1.4.4/containerd-1.4.4-linux-amd64.tar.gz
  
# configure containerd
mkdir containerd
tar -xvf crictl-v1.21.0-linux-amd64.tar.gz
tar -xvf containerd-1.4.4-linux-amd64.tar.gz -C containerd
sudo mv runc.amd64 runc
chmod +x crictl runc  
sudo mv crictl runc /usr/local/bin/
sudo mv containerd/bin/* /bin/
sudo mkdir -p /etc/containerd/

cat << EOF | sudo tee /etc/containerd/config.toml
[plugins]
  [plugins.cri.containerd]
    snapshotter = "overlayfs"
    [plugins.cri.containerd.default_runtime]
      runtime_type = "io.containerd.runtime.v1.linux"
      runtime_engine = "/usr/local/bin/runc"
      runtime_root = ""
EOF


# Create the containerd.service systemd unit file
cat <<EOF | sudo tee /etc/systemd/system/containerd.service
[Unit]
Description=containerd container runtime
Documentation=https://containerd.io
After=network.target

[Service]
ExecStartPre=/sbin/modprobe overlay
ExecStart=/bin/containerd
Restart=always
RestartSec=5
Delegate=yes
KillMode=process
OOMScoreAdjust=-999
LimitNOFILE=1048576
LimitNPROC=infinity
LimitCORE=infinity

[Install]
WantedBy=multi-user.target
EOF
```

5. Create directories for to configure `kubelet`, `kube-proxy`, `cni`, and a directory to keep the kubernetes root ca file
```bash
sudo mkdir -p \
  /var/lib/kubelet \
  /var/lib/kube-proxy \
  /etc/cni/net.d \
  /opt/cni/bin \
  /var/lib/kubernetes \
  /var/run/kubernetes
```

6. Download and Install CNI 
- Container Network Interface CNI: is a set of standards and libraries that define how programs(plugins) should be developed to solve networking challenges in a Container Runtime Environment
- Kubernetes uses CNI as an interface between network providers and Kubernetes Pod networking
- kubelet invokes the CNI plugins. CNI plugins get called when we start containers   
```bash
wget -q --show-progress --https-only --timestamping \
  https://github.com/containernetworking/plugins/releases/download/v0.9.1/cni-plugins-linux-amd64-v0.9.1.tgz
  
# Install CNI into /opt/cni/bin/. We will be using Flannel  
sudo tar -xvf cni-plugins-linux-amd64-v0.9.1.tgz -C /opt/cni/bin/
```

7. Download and install binaries for kubectl, kube-proxy, and kubelet
```bash
wget -q --show-progress --https-only --timestamping \
  https://storage.googleapis.com/kubernetes-release/release/v1.21.0/bin/linux/amd64/kubectl \
  https://storage.googleapis.com/kubernetes-release/release/v1.21.0/bin/linux/amd64/kube-proxy \
  https://storage.googleapis.com/kubernetes-release/release/v1.21.0/bin/linux/amd64/kubelet
  
chmod +x  kubectl kube-proxy kubelet 
sudo mv  kubectl kube-proxy kubelet /usr/local/bin/ 
```

### Configure Components
1. Kubelet
- The Pod Cidr is from terraform when create the ec2 instances
-  It is very important to ensure that the CIDR does not overlap with Node Instances IP
- In this case I used 10.xx.xx.xx cidr group for Nodes and 172.16.xx.xx for Pods
- Regardless of which node is running the container in the cluster(3 Nodes), Kubernetes expects that all the containers must be able to communicate with each other
- To mitigate security risks and have a better controlled network topology, Kubernetes uses CNI (Container Network Interface) to manage Network Policies which can be 
  used to operate the Pod network through external plugins such as Calico, Flannel or Weave Net to name a few.
```bash
POD_CIDR=$(curl -s http://169.254.169.254/latest/user-data/ \
  | tr "|" "\n" | grep "^pod-cidr" | cut -d"=" -f2)
echo "${POD_CIDR}"
```
- You must decide on the Pod CIDR per worker node. Each worker node will run multiple pods, and each pod will have its own IP address
